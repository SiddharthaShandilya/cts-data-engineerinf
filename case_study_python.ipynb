{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1aa6687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddhartha/spark-3.2.1-bin-hadoop3.2/python/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('first_app').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d205a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('StudentData.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200c932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: integer (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961dcc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+----------------+------+------------------+-----------------+--------------------+\n",
      "|summary|               age|gender|            name|course|              roll|            marks|               email|\n",
      "+-------+------------------+------+----------------+------+------------------+-----------------+--------------------+\n",
      "|  count|              1000|  1000|            1000|  1000|              1000|             1000|                1000|\n",
      "|   mean|            28.506|  null|            null|  null|       4997014.708|           60.097|                null|\n",
      "| stddev|0.5002141683461337|  null|            null|  null|2888208.5159476185|22.85537046208087|                null|\n",
      "|    min|                28|Female|     Abram Nagao| Cloud|              2984|               20|Abram Nagao_Celes...|\n",
      "|    max|                29|  Male|Toshiko Hillyard|    PF|           9991617|               99|Toshiko Hillyard_...|\n",
      "+-------+------------------+------+----------------+------+------------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920918bb",
   "metadata": {},
   "source": [
    "Q1)  Show the total number of Students in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74ef814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = df.groupBy(df['roll']).count()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f71015",
   "metadata": {},
   "source": [
    "Q2) total marks achieved by male and female students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e2cd236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|gender|sum(marks)|\n",
      "+------+----------+\n",
      "|Female|     29636|\n",
      "|  Male|     30461|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_q2 = df[\"gender\",\"marks\"]\n",
    "#df_q2.show()\n",
    "#total = df_q2.groupBy().sum()\n",
    "#total.show()\n",
    "#df_q2.filter(df[\"gender\"] == \"Male\").select(['marks']).sum()\n",
    "#spark.createDataFrame(a,[\"count\",\"country\"])\n",
    "#from pyspark.sql.functions import sum\n",
    "#df.filter(df['gender']==\"Male\").select(['marks']).sum().show()\n",
    "#male_total_marks = df.filter(df[\"gender\"] == \"Male\").select(['marks']).sum()\n",
    "\n",
    "\n",
    "\n",
    "df_q2 = df['gender', 'marks']\n",
    "total = df_q2.groupBy(\"gender\").sum()\n",
    "total.show()\n",
    "df_q2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356f982",
   "metadata": {},
   "source": [
    "Q3) Show the total number of students that have passed or failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bbca10f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of students passed are  644\n",
      "------------------------------------------------------------\n",
      "The total number of students passed are  356\n"
     ]
    }
   ],
   "source": [
    "#df.filter(df[marks] >=50).show()\n",
    "#result = spark.sql(\"select * from first_app where marks >= 50 \")\n",
    "\n",
    "#df_q3 = df[\"marks\"]\n",
    "#total = df_q3.filter(\"marks >=50 \").sum()\n",
    "df = spark.read.csv('StudentData.csv',inferSchema=True,header=True)\n",
    "passed = df.filter(df['marks'] >=50).select('marks').count()\n",
    "print(\"The total number of students passed are \",passed)\n",
    "print(\"--\"*30)\n",
    "failed = df.filter(df['marks'] <50).select('marks').count()\n",
    "print(\"The total number of students passed are \",failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f563b3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q4) show the total number of students enrolled per course\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bab9eaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "The total number of students enrolled per course are \n",
      "+------+-----+\n",
      "|course|count|\n",
      "+------+-----+\n",
      "|    PF|  166|\n",
      "|    DB|  157|\n",
      "|   MVC|  157|\n",
      "|   DSA|  176|\n",
      "| Cloud|  192|\n",
      "|   OOP|  152|\n",
      "+------+-----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('StudentData.csv',inferSchema=True,header=True)\n",
    "course_enrolled = df.groupBy(\"course\").count()\n",
    "\n",
    "print(\"--\"*30)\n",
    "print(\"The total number of students enrolled per course are \")\n",
    "print(course_enrolled.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1899e",
   "metadata": {},
   "source": [
    "Q5) show the total marks student achieved per course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6965c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|course|sum(marks)|\n",
      "+------+----------+\n",
      "|    PF|      9933|\n",
      "|    DB|      9270|\n",
      "|   MVC|      9585|\n",
      "|   DSA|     10950|\n",
      "| Cloud|     11443|\n",
      "|   OOP|      8916|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('StudentData.csv',inferSchema=True,header=True)\n",
    "df_q5 = df['course', 'marks']\n",
    "total = df_q5.groupBy(\"course\").sum()\n",
    "total.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635b41b",
   "metadata": {},
   "source": [
    "Q6) show the average marks student achieved per course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a38d3186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|course|        avg(marks)|\n",
      "+------+------------------+\n",
      "|    PF| 59.83734939759036|\n",
      "|    DB|59.044585987261144|\n",
      "|   MVC| 61.05095541401274|\n",
      "|   DSA| 62.21590909090909|\n",
      "| Cloud|59.598958333333336|\n",
      "|   OOP|  58.6578947368421|\n",
      "+------+------------------+\n",
      "\n",
      "------------------------------------------------------------\n",
      "+---------+\n",
      "|avg_marks|\n",
      "+---------+\n",
      "|    59.84|\n",
      "|    59.04|\n",
      "|    61.05|\n",
      "|    62.22|\n",
      "|    59.60|\n",
      "|    58.66|\n",
      "+---------+\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('StudentData.csv',inferSchema=True,header=True)\n",
    "df_q6 = df['course', 'marks']\n",
    "total = df_q6.groupBy(\"course\").mean()\n",
    "total.show()\n",
    "\n",
    "print(\"--\"*30)\n",
    "\n",
    "from pyspark.sql.functions import format_number\n",
    "total.select(format_number(total[1], 2).alias('avg_marks')).show()\n",
    "\n",
    "print(\"--\"*30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8da36",
   "metadata": {},
   "source": [
    "Q7) show the minimum and maximum marks student achieved per course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f54c4d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|course|min(marks)|\n",
      "+------+----------+\n",
      "|    PF|        20|\n",
      "|    DB|        20|\n",
      "|   MVC|        22|\n",
      "|   DSA|        20|\n",
      "| Cloud|        20|\n",
      "|   OOP|        20|\n",
      "+------+----------+\n",
      "\n",
      "+------+----------+\n",
      "|course|max(marks)|\n",
      "+------+----------+\n",
      "|    PF|        99|\n",
      "|    DB|        98|\n",
      "|   MVC|        99|\n",
      "|   DSA|        99|\n",
      "| Cloud|        99|\n",
      "|   OOP|        99|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('StudentData.csv',inferSchema=True,header=True)\n",
    "df_q7 = df['course', 'marks']\n",
    "min = df_q7.groupBy(\"course\").min().show()\n",
    "max = df_q7.groupBy(\"course\").max().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2da78e",
   "metadata": {},
   "source": [
    "Q8) show the average age of male and female students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "aa7c63ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|gender|          avg(age)|\n",
      "+------+------------------+\n",
      "|Female|28.489021956087825|\n",
      "|  Male| 28.52304609218437|\n",
      "+------+------------------+\n",
      "\n",
      "------------------------------------------------------------\n",
      "+-------+\n",
      "|avg_age|\n",
      "+-------+\n",
      "|  28.49|\n",
      "|  28.52|\n",
      "+-------+\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('StudentData.csv',inferSchema=True,header=True)\n",
    "df_q8 = df['gender', 'age']\n",
    "total = df_q8.groupBy(\"gender\").mean()\n",
    "total.show()\n",
    "\n",
    "print(\"--\"*30)\n",
    "\n",
    "from pyspark.sql.functions import format_number\n",
    "total.select(format_number(total[1], 2).alias('avg_age')).show()\n",
    "\n",
    "print(\"--\"*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394e563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
