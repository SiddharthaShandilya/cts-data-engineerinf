{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5230290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc, count\n",
    "spark = SparkSession.builder.appName('trial_mini_project').getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "# importing data from datastet\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "#df_q2 = df.select('Dest', 'TailNum').where(df[\"Dest\"] != '0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296e56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27ebf76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: string (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiIn: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: integer (nullable = true)\n",
      " |-- WeatherDelay: integer (nullable = true)\n",
      " |-- NASDelay: integer (nullable = true)\n",
      " |-- SecurityDelay: integer (nullable = true)\n",
      " |-- LateAircraftDelay: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c825b",
   "metadata": {},
   "source": [
    "# 1) Find the most frequent tail number which is getting in destination \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a02facb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      " +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++  +++++ \n",
      "+-------+----+-------------+\n",
      "|TailNum|Dest|Count_TailNum|\n",
      "+-------+----+-------------+\n",
      "| N655BR| HNL|         2241|\n",
      "| N651BR| HNL|         2173|\n",
      "| N654BR| HNL|         2138|\n",
      "| N693BR| HNL|         2067|\n",
      "| N479HA| HNL|         2038|\n",
      "| N478HA| HNL|         2024|\n",
      "| N485HA| HNL|         1984|\n",
      "| N480HA| HNL|         1976|\n",
      "| N484HA| HNL|         1944|\n",
      "| N487HA| HNL|         1909|\n",
      "| N481HA| HNL|         1868|\n",
      "| N810AL| HNL|         1843|\n",
      "| N477HA| HNL|         1837|\n",
      "| N837AL| HNL|         1836|\n",
      "| N475HA| HNL|         1816|\n",
      "| N486HA| HNL|         1787|\n",
      "| N646BR| HNL|         1768|\n",
      "| N836AL| HNL|         1761|\n",
      "| N824AL| HNL|         1754|\n",
      "| N808AL| HNL|         1740|\n",
      "+-------+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc,expr\n",
    "\n",
    "#importing data from local data folder\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "#selecting the required columns , this makes processing faster\n",
    "df_q2 = df.select('Dest','TailNum')\n",
    "\n",
    "df_q2_no_null = df_q2.filter((df_q2[\"TailNum\"] != \"0\") & (df_q2[\"TailNum\"] != \"000000\")) #removing rows with TailNum = 0/000000\n",
    "\n",
    "print(type(df_q2))\n",
    "print(\" +++++ \"*20)\n",
    "most_frequent = df_q2_no_null.groupBy(\"TailNum\",'Dest').agg(count(\"TailNum\").alias(\"Count_TailNum\")).sort(col(\"Count_TailNum\").desc()).show()\n",
    "\n",
    "#most_frequent.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b8e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baaa036e",
   "metadata": {},
   "source": [
    "# 2) Find out the cancelled flight  details for the last quarter of the year 2007\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f17928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2007|    8|         2|        4|     NA|       830|     NA|       930|           WN|        7|      0|               NA|            60|     NA|      NA|      NA|   DAL| HOU|     239|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "|2007|    8|         2|        4|     NA|      2000|     NA|      2055|           WN|       56|      0|               NA|            55|     NA|      NA|      NA|   HOU| DAL|     239|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "|2007|    8|         2|        4|     NA|      1855|     NA|      2035|           WN|      756|      0|               NA|           160|     NA|      NA|      NA|   MCO| MDW|     989|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "|2007|    8|         2|        4|     NA|       705|     NA|       840|           WN|     1423|      0|               NA|           155|     NA|      NA|      NA|   MCO| MDW|     989|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "|2007|    8|         2|        4|     NA|      1830|     NA|      2210|           WN|      867|      0|               NA|           160|     NA|      NA|      NA|   MDW| MCO|     989|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df.na.drop()\n",
    "df.filter((df.Month >= 8) & (df.Month <=12) & (df.Cancelled == 1)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65019c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7c678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af3f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3fb345b",
   "metadata": {},
   "source": [
    "# 3) Find out the average weather delays for a particular flight per month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ff23285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Month=1, avg(WeatherDelay)=0.8126742594025668),\n",
       " Row(Month=2, avg(WeatherDelay)=1.1426651862433788),\n",
       " Row(Month=3, avg(WeatherDelay)=0.6333765638468795),\n",
       " Row(Month=4, avg(WeatherDelay)=0.51643216930666),\n",
       " Row(Month=5, avg(WeatherDelay)=0.6052272846017077),\n",
       " Row(Month=6, avg(WeatherDelay)=1.2763936562420544),\n",
       " Row(Month=7, avg(WeatherDelay)=1.0766004687307265),\n",
       " Row(Month=8, avg(WeatherDelay)=0.8375915956275956),\n",
       " Row(Month=9, avg(WeatherDelay)=0.41135346150449775),\n",
       " Row(Month=10, avg(WeatherDelay)=0.45674389516057345),\n",
       " Row(Month=11, avg(WeatherDelay)=0.3357768086867862),\n",
       " Row(Month=12, avg(WeatherDelay)=1.1352771929481762)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "df.groupBy(\"Month\").avg('WeatherDelay').sort(col(\"Month\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d3841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05f751c4",
   "metadata": {},
   "source": [
    "# 4) Inspite of NASDelay, SecurityDelay, LateAircraftDelay,Weatherdealy which flight reached on time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f696d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "\n",
    "#NASDelay, SecurityDelay, LateAircraftDelay, Weatherdealy, ArrDelay\n",
    "#df.filter((df.Month >= 8) & (df.Month <=12) & (df.Cancelled == 1)).show()\n",
    "df.filter(((df.NASDelay > 0) | (df.SecurityDelay > 0) | (df.LateAircraftDelay > 0) | (df.WeatherDelay > 0)) & (df.ArrDelay <= 0) ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3873d80d",
   "metadata": {},
   "source": [
    "# 5) Month wise total distance travelled by each flight number in every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0fdd15a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+-----+-------------+\n",
      "|Month|sum(Distance)|\n",
      "+-----+-------------+\n",
      "|    1|    441687538|\n",
      "|    2|    402943192|\n",
      "|    3|    458766108|\n",
      "|    4|    441268345|\n",
      "|    5|    453440873|\n",
      "|    6|    456907218|\n",
      "|    7|    474040538|\n",
      "|    8|    473858891|\n",
      "|    9|    431198160|\n",
      "|   10|    450148203|\n",
      "|   11|    433902481|\n",
      "|   12|    446705757|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_q2 = df.select('Month','TailNum', 'Distance')\n",
    "\n",
    "print(type(df_q2))\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\").sum(\"Distance\").sort(col(\"Month\")).show()\n",
    "\n",
    "#total_count = df_q2.groupBy(\"TailNum\").sum(\"Distance\").sort(col(\"sum(Distance)\").desc()).show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0b342",
   "metadata": {},
   "source": [
    "# 6) Month wise how many flights get diverted(origin to destination)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10697b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|Month|sum(Diverted)|\n",
      "+-----+-------------+\n",
      "|    1|         1200|\n",
      "|    2|         1261|\n",
      "|    3|         1275|\n",
      "|    4|         1193|\n",
      "|    5|         1442|\n",
      "|    6|         2199|\n",
      "|    7|         2150|\n",
      "|    8|         2101|\n",
      "|    9|          962|\n",
      "|   10|         1000|\n",
      "|   11|          881|\n",
      "|   12|         1515|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_q2 = df.select('Month','Diverted')\n",
    "\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\").sum(\"Diverted\").sort(col(\"Month\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909260f",
   "metadata": {},
   "source": [
    "# 7) Week and month wise number of trips in all the flights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f58aa2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------+-----------+\n",
      "|Month|DayOfWeek|TailNum|total_trips|\n",
      "+-----+---------+-------+-----------+\n",
      "|    1|        1| N938UA|         21|\n",
      "|    1|        1|   N793|         17|\n",
      "|    1|        1| N27506|         13|\n",
      "|    1|        1| N444YV|         30|\n",
      "|    1|        1| N611SW|         39|\n",
      "|    1|        1| N594SW|         17|\n",
      "|    1|        1| N915EV|         24|\n",
      "|    1|        1| N509AA|         21|\n",
      "|    1|        1| N489UA|         14|\n",
      "|    1|        1| N679DA|         20|\n",
      "|    1|        1|  N6701|         11|\n",
      "|    1|        1| N919DL|         20|\n",
      "|    1|        1| N907EV|         23|\n",
      "|    1|        1| N981AT|         25|\n",
      "|    1|        1| N583NW|          9|\n",
      "|    1|        1| N304US|         20|\n",
      "|    1|        1| N372NW|         19|\n",
      "|    1|        1| N601NW|         25|\n",
      "|    1|        1| N5EFAA|         15|\n",
      "|    1|        1| N4YBAA|         16|\n",
      "+-----+---------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_no_cancel = df.filter('Cancelled== 0') \n",
    "df_q2 = df_no_cancel.select('Month','DayOfWeek','TailNum')\n",
    "\n",
    "\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\",'DayOfWeek','TailNum').agg(count(\"TailNum\").alias(\"total_trips\")).sort(['Month','DayOfWeek']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6778b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_distance.sort(['Month','DayOfWeek']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bba87f",
   "metadata": {},
   "source": [
    "# 8) Which flights covered maximum origin and destination by month wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86827c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a410f93a",
   "metadata": {},
   "source": [
    "# 9) Average month wise arrival delay (flightnum wise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5cc44144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------------------------+\n",
      "|Month|FlightNum|avg_monthly_arrival_delay|\n",
      "+-----+---------+-------------------------+\n",
      "|    1|       59|        6.102941176470588|\n",
      "|    1|      239|        6.021739130434782|\n",
      "|    1|     1972|        6.168539325842697|\n",
      "|    1|       96|       10.427631578947368|\n",
      "|    1|     2543|        5.857142857142857|\n",
      "|    1|     1670|        6.069767441860465|\n",
      "|    1|     1170|        19.62439024390244|\n",
      "|    1|     1839|       2.7282608695652173|\n",
      "|    1|     1703|         9.09727626459144|\n",
      "|    1|      318|        8.606666666666667|\n",
      "|    1|     2592|        1.911764705882353|\n",
      "|    1|     1185|        12.43661971830986|\n",
      "|    1|     1430|       15.057692307692308|\n",
      "|    1|     1799|        6.566666666666666|\n",
      "|    1|     2759|        42.69565217391305|\n",
      "|    1|     3058|       10.226666666666667|\n",
      "|    1|     3014|       1.8641975308641976|\n",
      "|    1|     2898|       0.7391304347826086|\n",
      "|    1|     7109|       16.894736842105264|\n",
      "|    1|     5448|       1.4259259259259258|\n",
      "+-----+---------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_no_cancel = df.filter('Cancelled== 0') \n",
    "df_q2 = df_no_cancel.select('Month','ArrDelay','FlightNum')\n",
    "\n",
    "\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\", \"FlightNum\").agg(avg(\"ArrDelay\").alias(\"avg_monthly_arrival_delay\")).sort(['Month']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd246c45",
   "metadata": {},
   "source": [
    "# 10) Average month wise departure delay (flightnum wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "665b3e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------------------+\n",
      "|Month|FlightNum|avg_monthly_departure_delay|\n",
      "+-----+---------+---------------------------+\n",
      "|    1|     2992|          7.778947368421052|\n",
      "|    1|     1167|           5.47093023255814|\n",
      "|    1|     2004|          6.402439024390244|\n",
      "|    1|     2099|         3.4107142857142856|\n",
      "|    1|     1912|         11.926470588235293|\n",
      "|    1|      864|          5.694117647058824|\n",
      "|    1|      838|         10.076086956521738|\n",
      "|    1|     1406|         10.136842105263158|\n",
      "|    1|     2994|                       9.95|\n",
      "|    1|     2843|          7.131147540983607|\n",
      "|    1|     2668|          6.383720930232558|\n",
      "|    1|     1192|                        8.0|\n",
      "|    1|     3021|                   -4.28125|\n",
      "|    1|     3030|          7.379310344827586|\n",
      "|    1|     3169|          80.33333333333333|\n",
      "|    1|     7157|          49.30555555555556|\n",
      "|    1|     7047|         37.027027027027025|\n",
      "|    1|     5025|          8.346153846153847|\n",
      "|    1|     5379|          5.633333333333334|\n",
      "|    1|     3803|          9.781609195402298|\n",
      "+-----+---------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_no_cancel = df.filter('Cancelled== 0') \n",
    "df_q2 = df_no_cancel.select('Month','DepDelay','FlightNum')\n",
    "\n",
    "\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\",\"FlightNum\").agg(avg(\"DepDelay\").alias(\"avg_monthly_departure_delay\")).sort(['Month']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a7e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515d444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
