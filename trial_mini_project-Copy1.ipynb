{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c7aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5230290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: string (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiIn: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: integer (nullable = true)\n",
      " |-- WeatherDelay: integer (nullable = true)\n",
      " |-- NASDelay: integer (nullable = true)\n",
      " |-- SecurityDelay: integer (nullable = true)\n",
      " |-- LateAircraftDelay: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc, count, window\n",
    "spark = SparkSession.builder.appName('trial_mini_project').getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "# importing data from datastet\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "#df_q2 = df.select('Dest', 'TailNum').where(df[\"Dest\"] != '0')\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c825b",
   "metadata": {},
   "source": [
    "# 1) Find the most frequent tail number which is getting in destination \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b94f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d48e1469",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8354f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flights that covered maximum Dest month wise\n",
      "+----+-------+-------------+\n",
      "|Dest|TailNum|Count_TailNum|\n",
      "+----+-------+-------------+\n",
      "| HNL| N655BR|         2227|\n",
      "| DEN| N455YV|         1377|\n",
      "| LAX| N313AE|         1250|\n",
      "| ORD| N680AE|         1177|\n",
      "| DFW| N286AE|         1161|\n",
      "| PHX| N988HA|         1079|\n",
      "| SEA| N556AS|         1076|\n",
      "| ATL| N634AS|         1017|\n",
      "| LGA| N916DE|         1003|\n",
      "| IAH| N15941|          994|\n",
      "| SLC| N457SW|          982|\n",
      "| OGG| N479HA|          853|\n",
      "| SJC| N841AE|          835|\n",
      "| CVG| N656CA|          760|\n",
      "| CLT| N906FJ|          706|\n",
      "| JFK| N197JB|          702|\n",
      "| ANC| N768AS|          701|\n",
      "| IAD| N859MJ|          676|\n",
      "| SFO| N293SW|          668|\n",
      "| PHL| N944UW|          636|\n",
      "+----+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc, count, countDistinct, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "#importing data from local data folder\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "df_q1 = df\n",
    "df_q1.na.drop(subset=['TailNum','Dest','Month'])\n",
    "\n",
    "#Calculating which flights covered maximum origins by month wise\n",
    "\n",
    "df_q11 = df_q1.filter(df_q1.Cancelled == 0).groupBy('Dest','TailNum').agg(count('TailNum').alias(\"Count_TailNum\")).sort(desc('Count_TailNum'))\n",
    "\n",
    "\n",
    "maxDest = Window.partitionBy('Dest').orderBy(col(\"Count_TailNum\").desc())\n",
    "\n",
    "\n",
    "flight_with_maxDest = df_q11.withColumn(\"row\",row_number().over(maxDest)).filter(col(\"row\") == 1).drop(\"row\")\n",
    "\n",
    "print(\"Flights that covered maximum Dest month wise\")\n",
    "\n",
    "flight_with_maxDest.sort(desc('Count_TailNum')).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee42bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import avg, col, desc, count, window\\n#importing data from local data folder\\ndf = spark.read.csv(\\'Data/2007.csv\\',inferSchema=True,header=True)\\n\\n#selecting the required columns , this makes processing faster\\ndf_q2 = df.select(\\'Dest\\',\\'TailNum\\', \\'Cancelled\\')\\n\\ndf_q2_no_null = df_q2.filter((df_q2[\"TailNum\"] != \"0\") & (df_q2[\"TailNum\"] != \"000000\") & (df_q2[\"Cancelled\"] != 1)) #removing rows with TailNum = 0/000000\\n\\n#print(type(df_q2))\\nprint(\" +++++ \"*10)\\nmost_frequent = df_q2_no_null.groupBy(\"TailNum\",\\'Dest\\').agg(count(\"TailNum\").alias(\"Count_TailNum\")).sort(col(\"Count_TailNum\").desc()).show(1000)\\n\\n\\n#most_frequent.distinct().show()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc, count, window\n",
    "#importing data from local data folder\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "#selecting the required columns , this makes processing faster\n",
    "df_q2 = df.select('Dest','TailNum', 'Cancelled')\n",
    "\n",
    "df_q2_no_null = df_q2.filter((df_q2[\"TailNum\"] != \"0\") & (df_q2[\"TailNum\"] != \"000000\") & (df_q2[\"Cancelled\"] != 1)) #removing rows with TailNum = 0/000000\n",
    "\n",
    "#print(type(df_q2))\n",
    "print(\" +++++ \"*10)\n",
    "most_frequent = df_q2_no_null.groupBy(\"TailNum\",'Dest').agg(count(\"TailNum\").alias(\"Count_TailNum\")).sort(col(\"Count_TailNum\").desc()).show(1000)\n",
    "\n",
    "\n",
    "#most_frequent.distinct().show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a67ec",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa036e",
   "metadata": {},
   "source": [
    "# 2) Find out the cancelled flight  details for the last quarter of the year 2007\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3681b4e",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f17928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2007|   10|         2|        2|     NA|      1930|     NA|      2150|           WN|      195|      0|               NA|            80|     NA|      NA|      NA|   LAS| ABQ|     487|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "|2007|   10|         2|        2|     NA|      2105|     NA|      2210|           WN|      710|      0|               NA|            65|     NA|      NA|      NA|   LAS| LAX|     236|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "|2007|   10|         2|        2|     NA|      1555|     NA|      2125|           WN|     1191|      0|               NA|           210|     NA|      NA|      NA|   LAS| MDW|    1521|     0|      0|        1|               B|       0|           0|           0|       0|            0|                0|\n",
      "|2007|   10|         2|        2|     NA|       730|     NA|       840|           WN|      514|      0|               NA|            70|     NA|      NA|      NA|   LAS| PHX|     256|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "|2007|   10|         2|        2|     NA|       635|     NA|       810|           WN|     1799|      0|               NA|            95|     NA|      NA|      NA|   LAS| SFO|     414|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "df.na.drop()\n",
    "\n",
    "df.filter((df.Month >=10) & (df.Month <=12) & (df.Cancelled == 1)).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af3f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3add3fb8",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb345b",
   "metadata": {},
   "source": [
    "# 3) Find out the average weather delays for a particular flight per month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca231655",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff23285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|Month|  avg(WeatherDelay)|\n",
      "+-----+-------------------+\n",
      "|    1| 0.8126742594025668|\n",
      "|    2| 1.1426651862433788|\n",
      "|    3| 0.6333765638468795|\n",
      "|    4|   0.51643216930666|\n",
      "|    5| 0.6052272846017077|\n",
      "|    6| 1.2763936562420544|\n",
      "|    7| 1.0766004687307265|\n",
      "|    8| 0.8375915956275956|\n",
      "|    9|0.41135346150449775|\n",
      "|   10|0.45674389516057345|\n",
      "|   11| 0.3357768086867862|\n",
      "|   12| 1.1352771929481762|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "df.groupBy(\"Month\").avg('WeatherDelay').sort(col(\"Month\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e97f5",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d3841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05f751c4",
   "metadata": {},
   "source": [
    "# 4) Inspite of NASDelay, SecurityDelay, LateAircraftDelay,Weatherdealy which flight reached on time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3ec93",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f696d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "\n",
    "df.filter(((df.NASDelay > 0) | (df.SecurityDelay > 0) | (df.LateAircraftDelay > 0) | (df.WeatherDelay > 0)) & (df.ArrDelay <= 0) ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6cd64b",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3873d80d",
   "metadata": {},
   "source": [
    "# 5) Month wise total distance travelled by each flight number in every month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402c0b7",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fdd15a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+-----+---------+-------------+\n",
      "|Month|FlightNum|sum(Distance)|\n",
      "+-----+---------+-------------+\n",
      "|    1|      739|       218313|\n",
      "|    1|     2344|        71799|\n",
      "|    1|     2285|        39326|\n",
      "|    1|     2847|        73732|\n",
      "|    1|      547|       215454|\n",
      "|    1|     1726|       139989|\n",
      "|    1|     2367|       103377|\n",
      "|    1|     2478|        76863|\n",
      "|    1|      847|       103350|\n",
      "|    1|      381|       263587|\n",
      "|    1|      152|       347567|\n",
      "|    1|      541|       170169|\n",
      "|    1|     2215|        54846|\n",
      "|    1|     2682|        32871|\n",
      "|    1|     2250|        36816|\n",
      "|    1|     1207|       130163|\n",
      "|    1|     2267|        28446|\n",
      "|    1|     2699|        12831|\n",
      "|    1|     7187|         5328|\n",
      "|    1|     7174|        29747|\n",
      "+-----+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_q2 = df.select('Month','FlightNum', 'Distance').filter((df[\"TailNum\"] != \"0\") & (df[\"TailNum\"] != \"000000\"))\n",
    "\n",
    "print(type(df_q2))\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\",\"FlightNum\").sum(\"Distance\").sort(col(\"Month\")).show()\n",
    "\n",
    "#total_count = df_q2.groupBy(\"TailNum\").sum(\"Distance\").sort(col(\"sum(Distance)\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2757ce5",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0b342",
   "metadata": {},
   "source": [
    "# 6) Month wise how many flights get diverted(origin to destination)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe7b5f",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10697b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++ \n",
      "+-----+-------------+\n",
      "|Month|sum(Diverted)|\n",
      "+-----+-------------+\n",
      "|    1|         1200|\n",
      "|    2|         1261|\n",
      "|    3|         1275|\n",
      "|    4|         1193|\n",
      "|    5|         1442|\n",
      "|    6|         2199|\n",
      "|    7|         2150|\n",
      "|    8|         2100|\n",
      "|    9|          942|\n",
      "|   10|          977|\n",
      "|   11|          845|\n",
      "|   12|         1488|\n",
      "+-----+-------------+\n",
      "\n",
      " ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++ \n",
      "+-----+------+----+-------------+\n",
      "|Month|Origin|Dest|sum(Diverted)|\n",
      "+-----+------+----+-------------+\n",
      "|    1|   STL| TUL|            0|\n",
      "|    1|   TPA| PHX|            1|\n",
      "|    1|   DEN| LAS|            0|\n",
      "|    1|   MCI| SEA|            0|\n",
      "|    1|   MCO| ISP|            1|\n",
      "|    1|   PDX| GEG|            0|\n",
      "|    1|   IAH| MOB|            0|\n",
      "|    1|   SDF| IAH|            0|\n",
      "|    1|   CMH| DCA|            0|\n",
      "|    1|   ATL| LEX|            0|\n",
      "|    1|   CVG| IAD|            0|\n",
      "|    1|   HSV| DCA|            0|\n",
      "+-----+------+----+-------------+\n",
      "only showing top 12 rows\n",
      "\n",
      " ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++  ++++ \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_q2 = df.select('Origin','Month','Dest','TailNum','Diverted').filter((df[\"TailNum\"] != \"0\") & (df[\"TailNum\"] != \"000000\"))\n",
    "\n",
    "print(\" ++++ \"*10)\n",
    "\n",
    "# monthwise total diveted flight\n",
    "total_sum_diverted = df_q2.groupBy(\"Month\").sum(\"Diverted\").sort(col(\"Month\")).show()\n",
    "\n",
    "print(\" ++++ \"*10)\n",
    "\n",
    "# monthwise total diveted flight with respect to each origin and destination\n",
    "total_distance = df_q2.groupBy(\"Month\",'Origin','Dest').sum(\"Diverted\").sort(col(\"Month\")).show(12)\n",
    "\n",
    "print(\" ++++ \"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c5762",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909260f",
   "metadata": {},
   "source": [
    "# 7) Week and month wise number of trips in all the flights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4676dca",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58aa2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------+-----------+\n",
      "|Month|DayOfWeek|TailNum|total_trips|\n",
      "+-----+---------+-------+-----------+\n",
      "|    1|        1| N938UA|         21|\n",
      "|    1|        1|   N793|         17|\n",
      "|    1|        1| N27506|         13|\n",
      "|    1|        1| N444YV|         30|\n",
      "|    1|        1| N611SW|         39|\n",
      "|    1|        1| N594SW|         17|\n",
      "|    1|        1| N915EV|         24|\n",
      "|    1|        1| N509AA|         21|\n",
      "|    1|        1| N489UA|         14|\n",
      "|    1|        1| N679DA|         20|\n",
      "|    1|        1|  N6701|         11|\n",
      "|    1|        1| N919DL|         20|\n",
      "|    1|        1| N907EV|         23|\n",
      "|    1|        1| N981AT|         25|\n",
      "|    1|        1| N583NW|          9|\n",
      "|    1|        1| N304US|         20|\n",
      "|    1|        1| N372NW|         19|\n",
      "|    1|        1| N601NW|         25|\n",
      "|    1|        1| N5EFAA|         15|\n",
      "|    1|        1| N4YBAA|         16|\n",
      "+-----+---------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_no_cancel = df.filter('Cancelled== 0') \n",
    "df_q2 = df_no_cancel.select('Month','DayOfWeek','TailNum').filter((df[\"TailNum\"] != \"0\") & (df[\"TailNum\"] != \"000000\") & (df[\"Cancelled\"] == 0))\n",
    "\n",
    "\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\",'DayOfWeek','TailNum').agg(count(\"TailNum\").alias(\"total_trips\")).sort(['Month','DayOfWeek']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48cc1f",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6778b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_distance.sort(['Month','DayOfWeek']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bba87f",
   "metadata": {},
   "source": [
    "# 8) Which flights covered maximum origin and destination by month wise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa6c7d",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba86827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      " --++--   --++--   --++--   --++--   --++--   --++--   --++--   --++--   --++--   --++--   \n",
      " With respect to Tail Number \n",
      " --++--  --++--  --++--  --++--  --++--  --++--  --++--  --++--  --++--  --++-- \n",
      "+-----+------+----+-------+-------------------+\n",
      "|Month|Origin|Dest|TailNum|Total_trips_TailNum|\n",
      "+-----+------+----+-------+-------------------+\n",
      "|    8|   HNL| OGG| N841AL|                 94|\n",
      "|    7|   HNL| OGG| N841AL|                 86|\n",
      "|   12|   OGG| HNL| N841AL|                 86|\n",
      "|   12|   HNL| OGG| N841AL|                 86|\n",
      "|    8|   OGG| HNL| N485HA|                 85|\n",
      "|   10|   HNL| KOA| N655BR|                 84|\n",
      "|   10|   KOA| HNL| N655BR|                 84|\n",
      "|    1|   KOA| HNL| N646BR|                 83|\n",
      "|    1|   HNL| KOA| N646BR|                 82|\n",
      "|    7|   LIH| HNL| N841AL|                 80|\n",
      "|    5|   HNL| OGG| N836AL|                 79|\n",
      "|    5|   BOS| LGA| N908DE|                 78|\n",
      "|   10|   LGA| BOS| N911DE|                 78|\n",
      "|   10|   BOS| LGA| N911DE|                 78|\n",
      "|    8|   KOA| HNL| N655BR|                 78|\n",
      "|    5|   LGA| BOS| N908DE|                 78|\n",
      "|    8|   HNL| KOA| N655BR|                 78|\n",
      "|    7|   LGA| BOS| N913DE|                 77|\n",
      "|   11|   BOS| LGA| N916DE|                 76|\n",
      "|    7|   BOS| LGA| N913DE|                 76|\n",
      "+-----+------+----+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      " --++--   --++--   --++--   --++--   --++--   --++--   --++--   --++--   --++--   --++--   \n",
      " With respect to Flight Number \n",
      " --++--  --++--  --++--  --++--  --++--  --++--  --++--  --++--  --++--  --++-- \n",
      "+-----+------+----+---------+---------------------+\n",
      "|Month|Origin|Dest|FlightNum|Total_trips_FlightNum|\n",
      "+-----+------+----+---------+---------------------+\n",
      "|    7|   LAX| HNL|        3|                   62|\n",
      "|    8|   JFK| SFO|       15|                   62|\n",
      "|    8|   LAX| JFK|       30|                   62|\n",
      "|    8|   DEN| SLC|      141|                   62|\n",
      "|    5|   JFK| LAX|      133|                   62|\n",
      "|    1|   LAX| JFK|       30|                   62|\n",
      "|    7|   JFK| LAX|      133|                   62|\n",
      "|    1|   OGG| KOA|       94|                   62|\n",
      "|   10|   JFK| LAX|      133|                   62|\n",
      "|    1|   LIH| HNL|      110|                   62|\n",
      "|    1|   SFO| JFK|       16|                   62|\n",
      "|   10|   ATL| MEM|      536|                   62|\n",
      "|    3|   ORD| SAN|      309|                   62|\n",
      "|    1|   ORD| FLL|     1498|                   62|\n",
      "|    7|   SAN| PHX|      614|                   62|\n",
      "|    5|   SFO| SEA|      295|                   62|\n",
      "|   12|   ATL| DFW|     1209|                   62|\n",
      "|   10|   LAX| JFK|       30|                   62|\n",
      "|   10|   JFK| SFO|       15|                   61|\n",
      "|   12|   JFK| MCO|       79|                   61|\n",
      "+-----+------+----+---------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc,expr\n",
    "\n",
    "#importing data from local data folder\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "#selecting the required columns , this makes processing faster\n",
    "df_q2 = df.select('Origin','Month','Dest','TailNum','FlightNum','Cancelled').filter((df[\"TailNum\"] != \"0\") & (df[\"TailNum\"] != \"000000\"))\n",
    "\n",
    "df_q2_no_null = df_q2.filter((df_q2[\"Origin\"] != \"null\") & (df_q2[\"Dest\"] != \"null\") & (df_q2[\"Cancelled\"] != 1) ) #removing rows with null values\n",
    "\n",
    "print(type(df_q2))\n",
    "\n",
    "print(\" --++--  \"*10 + \" \\n With respect to Tail Number \\n\" + \" --++-- \"*10)\n",
    "\n",
    "most_frequent_TailNum = df_q2_no_null.groupBy('Month','Origin','Dest','TailNum').agg(count(\"TailNum\").alias(\"Total_trips_TailNum\")).sort(col(\"Total_trips_TailNum\").desc()).show()\n",
    "\n",
    "print(\" --++--  \"*10 + \" \\n With respect to Flight Number \\n\" + \" --++-- \"*10)\n",
    "\n",
    "most_frequent_FlightNum = df_q2_no_null.groupBy('Month','Origin','Dest','FlightNum').agg(count(\"FlightNum\").alias(\"Total_trips_FlightNum\")).sort(col(\"Total_trips_FlightNum\").desc())\n",
    "\n",
    "most_frequent_FlightNum.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9700e907",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4222c7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flights that covered maximum origins month wise\n",
      "+-----+------+----+---------+---------------------+\n",
      "|Month|Origin|Dest|FlightNum|Total_trips_FlightNum|\n",
      "+-----+------+----+---------+---------------------+\n",
      "|    5|   ADK| AKN|      139|                    9|\n",
      "|   10|   ATL| GSP|      678|                   31|\n",
      "|    2|   AVP| JFK|     4941|                    1|\n",
      "|    8|   BFL| SAN|      446|                   31|\n",
      "|    5|   BQN| MCO|      724|                   31|\n",
      "|    3|   CLE| SJU|     1412|                    5|\n",
      "|    1|   EWR| STT|     1884|                   31|\n",
      "|    5|   FSD| ATL|     5344|                   31|\n",
      "|    8|   LAS| LIT|     1045|                   31|\n",
      "|    3|   LAX| OXR|     6103|                   31|\n",
      "|    1|   MCI| IAH|     2547|                   31|\n",
      "|   12|   MLI| MCO|      392|                   15|\n",
      "|    3|   MSP| AVL|     2900|                   31|\n",
      "|    7|   ORD| PDX|      671|                   31|\n",
      "|    8|   PBI| DCA|     1282|                   31|\n",
      "|   10|   PHL| MCO|      617|                   31|\n",
      "|   10|   ROC| CLE|     2229|                   27|\n",
      "|    7|   SFO| PMD|     6456|                   31|\n",
      "|    8|   SMF| BUR|     1588|                   31|\n",
      "|   10|   SNA| PHX|     2091|                   31|\n",
      "+-----+------+----+---------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc, count, countDistinct, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "#importing data from local data folder\n",
    "df = most_frequent_FlightNum\n",
    "maxorigin = Window.partitionBy('Origin','Dest').orderBy(col(\"Total_trips_FlightNum\").desc())\n",
    "\n",
    "flight_with_maxorigin = df.withColumn(\"row\",row_number().over(maxorigin)).filter(col(\"row\") == 1).drop(\"row\")\n",
    "\n",
    "print(\"Flights that covered maximum origins month wise\")\n",
    "\n",
    "flight_with_maxorigin.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb48cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1252fe81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8cadd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flights that covered maximum origins month wise\n",
      "+-----+---------+-----------+\n",
      "|Month|FlightNum|Max_Origins|\n",
      "+-----+---------+-----------+\n",
      "|   12|      151|         22|\n",
      "|    1|      433|         18|\n",
      "|    6|      226|         18|\n",
      "|    3|      644|         18|\n",
      "|    5|      644|         17|\n",
      "|    9|       62|         20|\n",
      "|    4|      644|         17|\n",
      "|    8|       67|         18|\n",
      "|    7|      425|         17|\n",
      "|   10|       66|         20|\n",
      "|   11|      303|         21|\n",
      "|    2|      500|         18|\n",
      "+-----+---------+-----------+\n",
      "\n",
      "Flights that covered maximum destinations month wise\n",
      "+-----+---------+----------------+\n",
      "|Month|FlightNum|Max_Destinations|\n",
      "+-----+---------+----------------+\n",
      "|   12|      151|              20|\n",
      "|    1|      372|              18|\n",
      "|    6|      308|              18|\n",
      "|    3|      432|              17|\n",
      "|    5|      644|              19|\n",
      "|    9|      385|              18|\n",
      "|    4|      473|              17|\n",
      "|    8|       67|              18|\n",
      "|    7|      425|              17|\n",
      "|   10|       66|              20|\n",
      "|   11|      303|              21|\n",
      "|    2|      432|              17|\n",
      "+-----+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8.Which flights covered maximum origin and destination by month wise\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc,expr\n",
    "\n",
    "#importing data from local data folder\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "\n",
    "#Removing null values\n",
    "df8=df\n",
    "df8.na.drop(subset=['Origin','Dest','Month','FlightNum','Cancelled'])\n",
    "\n",
    "#Calculating which flights covered maximum origins by month wise\n",
    "\n",
    "df81 = df8.filter(df8.Cancelled == 0).groupBy('Month', 'FlightNum').agg(countDistinct('Origin').alias(\"Max_Origins\")).sort('Month', desc('Max_Origins'))\n",
    "\n",
    "maxorigin = Window.partitionBy('Month').orderBy(col(\"Max_Origins\").desc())\n",
    "\n",
    "flight_with_maxorigin = df81.withColumn(\"row\",row_number().over(maxorigin)).filter(col(\"row\") == 1).drop(\"row\")\n",
    "\n",
    "print(\"Flights that covered maximum origins month wise\")\n",
    "\n",
    "flight_with_maxorigin.show()\n",
    "\n",
    "#Calculating which flights covered maximum destinations by month wise\n",
    "\n",
    "df82 = df8.filter(df8.Cancelled == 0).groupBy('Month', 'FlightNum').agg(countDistinct('Dest').alias(\"Max_Destinations\")).sort('Month', desc('Max_Destinations'))\n",
    "\n",
    "maxdest = Window.partitionBy('Month').orderBy(col(\"Max_Destinations\").desc())\n",
    "\n",
    "flight_with_maxdest=df82.withColumn(\"row\",row_number().over(maxdest)).filter(col(\"row\") == 1).drop(\"row\")\n",
    "\n",
    "print(\"Flights that covered maximum destinations month wise\")\n",
    "\n",
    "flight_with_maxdest.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce2414",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a410f93a",
   "metadata": {},
   "source": [
    "# 9) Average month wise arrival delay (flightnum wise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dae29",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc44144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------------------------+\n",
      "|Month|FlightNum|avg_monthly_arrival_delay|\n",
      "+-----+---------+-------------------------+\n",
      "|    1|       59|        6.102941176470588|\n",
      "|    1|      239|        6.021739130434782|\n",
      "|    1|     1972|        6.168539325842697|\n",
      "|    1|       96|       10.427631578947368|\n",
      "|    1|     2543|        5.857142857142857|\n",
      "|    1|     1670|        6.069767441860465|\n",
      "|    1|     1170|        19.62439024390244|\n",
      "|    1|     1839|       2.7282608695652173|\n",
      "|    1|     1703|         9.09727626459144|\n",
      "|    1|      318|        8.606666666666667|\n",
      "|    1|     2592|        1.911764705882353|\n",
      "|    1|     1185|        12.43661971830986|\n",
      "|    1|     1430|       15.057692307692308|\n",
      "|    1|     1799|        6.566666666666666|\n",
      "|    1|     2759|        42.69565217391305|\n",
      "|    1|     3058|       10.226666666666667|\n",
      "|    1|     3014|       1.8641975308641976|\n",
      "|    1|     2898|       0.7391304347826086|\n",
      "|    1|     7109|       16.894736842105264|\n",
      "|    1|     5448|       1.4259259259259258|\n",
      "+-----+---------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_no_cancel = df.filter('Cancelled== 0') \n",
    "df_q2 = df_no_cancel.select('Month','ArrDelay','FlightNum')\n",
    "\n",
    "\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\", \"FlightNum\").agg(avg(\"ArrDelay\").alias(\"avg_monthly_arrival_delay\")).sort(['Month']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c20f9ca",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd246c45",
   "metadata": {},
   "source": [
    "# 10) Average month wise departure delay (flightnum wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f181a41",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665b3e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------------------+\n",
      "|Month|FlightNum|avg_monthly_departure_delay|\n",
      "+-----+---------+---------------------------+\n",
      "|    1|      739|         3.3737864077669903|\n",
      "|    1|     2344|           7.40952380952381|\n",
      "|    1|     2285|         -4.232558139534884|\n",
      "|    1|     2847|          5.572327044025157|\n",
      "|    1|      547|          17.09205020920502|\n",
      "|    1|     1726|          5.578231292517007|\n",
      "|    1|     2367|         3.8255813953488373|\n",
      "|    1|     2478|       0.033707865168539325|\n",
      "|    1|      847|         12.486842105263158|\n",
      "|    1|      381|         4.7611940298507465|\n",
      "|    1|      152|                  4.8515625|\n",
      "|    1|      541|         12.436681222707424|\n",
      "|    1|     2215|         1.4193548387096775|\n",
      "|    1|     2682|          8.419354838709678|\n",
      "|    1|     2250|         2.6056338028169015|\n",
      "|    1|     1207|          9.425531914893616|\n",
      "|    1|     2267|         31.345454545454544|\n",
      "|    1|     2699|          5.810344827586207|\n",
      "|    1|     7187|                     34.125|\n",
      "|    1|     7174|         13.311475409836065|\n",
      "+-----+---------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, desc\n",
    "\n",
    "\n",
    "df = spark.read.csv('Data/2007.csv',inferSchema=True,header=True)\n",
    "df_no_cancel = df.filter('Cancelled== 0') \n",
    "df_q2 = df_no_cancel.select('Month','DepDelay','FlightNum')\n",
    "\n",
    "\n",
    "\n",
    "total_distance = df_q2.groupBy(\"Month\",\"FlightNum\").agg(avg(\"DepDelay\").alias(\"avg_monthly_departure_delay\")).sort(['Month']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b974b50",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a7e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515d444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
